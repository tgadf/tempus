{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tempus Data Science Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to build a predictive model on the Tempus Data Science case study dataset. The data provided contains containing 16,562 features and a single response variable. This is a typical binary classification problem with the goal of creating a function, or model, that can distinguish data taken from the positive (i.e., 1) response set and data taken from the negative (i.e., 0) response set.\n",
    "\n",
    "The scikit-learn Python framework and the Pandas library are employed to ingest the dataset, build the classification model, and show the model performance. The data is processed and transformed in the Model Inputs section. Three binary classifiers are constructed in the Model Building section, and finally, the performance of the three models is explained in the Model Performance section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook Last Run Initiated: 2019-01-30 13:38:16.924013\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "start = dt.datetime.now()\n",
    "print(\"Notebook Last Run Initiated: \"+str(start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Python Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.6 |Anaconda custom (64-bit)| (default, Jun 28 2018, 11:07:29) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n"
     ]
    }
   ],
   "source": [
    "from numpy import reshape\n",
    "from pandas import DataFrame, Series, to_datetime\n",
    "import xgboost\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score    \n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from transform import transformData\n",
    "\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(530, 16563)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "data = read_csv(\"data.txt\", delimiter='\\t')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['response', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9',\n",
       "       ...\n",
       "       'V16553', 'V16554', 'V16555', 'V16556', 'V16557', 'V16558', 'V16559',\n",
       "       'V16560', 'V16561', 'V16562'],\n",
       "      dtype='object', length=16563)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['response']  ## y is the response data also known as the target variable\n",
    "X = data.drop('response', axis=1)  ## X is the predictor data also known collectively as the feature dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the overwhemingly large number of columns it is import to remove features (i.e., columns) with little variance or little correlation with the target. Keeping these columns could easily lead to overfitting. If there were more rows this requirement could be loosened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are correctly 16562 columns in the data\n",
      "There are now 2055 columns in the data\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold(threshold=0.1)\n",
    "print(\"There are correctly {0} columns in the data\".format(X.shape[1]))\n",
    "X = sel.fit_transform(X)\n",
    "print(\"There are now {0} columns in the data\".format(X.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scikit-learn train/test split function is employed to randomly create mutually exclusive training and testing datasets. If this step were not run it would lead to \"leakage\" and result in an overestimation of the actual model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create three binary classifier functions that access the underlying algorithms in the scikit-learn and xgboost libraries. The three algoritms are chosen based on previous experience using these models. The simplest and least complex model is Logistic Regression, which has no internal tunable parameters. The Random Forest model is known as an ensemble model that is constructed from a collection, or ensemble, of decision trees created using a random set of features. The third model, Xgboost, is an improved gradient boosted decision tree model this is known to perform extremely well on a wide variety of problems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainLogReg(X_train, y_train):\n",
    "    name = 'logreg'\n",
    "    glm = LogisticRegression()\n",
    "    model = trainEstimator(name, glm, X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainRF(X_train, y_train):\n",
    "    name = 'rf'\n",
    "    rf = RandomForestClassifier(n_estimators=50)\n",
    "    model = trainEstimator(name, rf, X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainXGboost(X_train, y_train):\n",
    "    name = 'xgb'\n",
    "    xgb = xgboost.XGBClassifier(n_jobs=1)\n",
    "    model = trainEstimator(name, xgb, X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the models without tuning any available hyperparameters. If there were more data, tuning these parameters would likely result in improved models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = trainLogReg(X_train, y_train)\n",
    "rf     = trainRF(X_train, y_train)\n",
    "xgb    = trainXGboost(X_train, y_train)\n",
    "models = {\"logreg\": logreg, \"xgb\": xgb, \"rf\": rf}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the trained models to predict the response on the as-yet-unseen test data. The relative difference between the predicted response and the actual test response serves as the model performance shown in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "perfs = {}\n",
    "for modelname, model in models.items():\n",
    "    y_probs  = model.predict_proba(X_test)[:,1]\n",
    "    y_probs  = Series(data=y_probs, name=\"predicted\")\n",
    "    y_preds  = model.predict(X_test)\n",
    "    y_preds  = Series(data=y_preds, name=\"predicted\")\n",
    "    perfs[modelname] = {\"Probs\": y_probs, \"Preds\": y_preds}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the standard suite of binary classification performance metrics. The most common of these are the true-positive rate (TPR) and fake-positive rate (FPR), which respresent the fraction of events that we correctly and incorrectly assigned to the true response value. From these values, the reciever-operator curve (ROC) can be constructed to visualize the performance of the models and compare them the case of a random and perfect prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelperfdata = {}\n",
    "for modelname,modeldata in perfs.items():\n",
    "    retval = {}\n",
    "    y_truth = y_test\n",
    "    y_probs = modeldata['Probs']\n",
    "    y_preds = modeldata['Preds']\n",
    "    precision, recall, pr_thresholds = precision_recall_curve(y_truth, y_probs)\n",
    "    retval[\"PR\"] = {\"precision\": precision, \"recall\": recall, \"thresholds\": pr_thresholds}\n",
    "\n",
    "    fpr, tpr, roc_thresholds = roc_curve(y_truth, y_probs)\n",
    "    retval[\"ROC\"] = {\"fpr\": fpr, \"tpr\": tpr, \"thresholds\": roc_thresholds}\n",
    "\n",
    "    auc = roc_auc_score(y_truth, y_probs)\n",
    "    retval[\"AUC\"] = auc\n",
    "\n",
    "    cfm = confusion_matrix(y_truth, y_preds)\n",
    "    tn, fp, fn, tp = cfm.ravel()\n",
    "    retval[\"Confusion\"] = {\"matrix\": cfm, \"tn\": tn, \"tp\": tp, \"fn\": fn, \"fp\": fp}\n",
    "    \n",
    "    modelperfdata[modelname] = retval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful metric is the confusion matrix, which shows the number of true-positive (TP) predictions, false-negative (FN) predictions, true-negative (TN) preduction, and false-positive (FP) prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix for logreg is [[125   1]\n",
      " [ 29  20]]\n",
      "The confusion matrix for xgb is [[125   1]\n",
      " [ 22  27]]\n",
      "The confusion matrix for rf is [[125   1]\n",
      " [ 41   8]]\n"
     ]
    }
   ],
   "source": [
    "for modelname, perfdata in modelperfdata.items():\n",
    "    mat = perfdata[\"Confusion\"]['matrix']\n",
    "    print(\"The confusion matrix for {0} is {1}\".format(modelname, mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the ROC curve for each classifier and show the area-under-the-curve (AUC) for each. The AUC is the integral (area) of the ROC curve between 0 and 1. A random prediction model (e.g., coin flip) will have an AUC value of 0.5. A perfect model will have an AUC value of 1, and all other models have values between 0.5 and 1. Models with values closer to 1 are better models (i.e., predict more correct responses) than models with values closer to 0.5 (i.e., predict few correct responses)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC for logreg is 0.82\n",
      "The AUC for xgb is 0.81\n",
      "The AUC for rf is 0.81\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a2aecca20>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "perfdata = retval\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure()\n",
    "current_palette = sns.color_palette()\n",
    "i = 0\n",
    "for modelname, perfdata in modelperfdata.items():\n",
    "    #colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "    auc = perfdata['AUC']\n",
    "    print(\"The AUC for {0} is {1}\".format(modelname, round(auc,2)))\n",
    "    tpr = perfdata['ROC']['tpr']\n",
    "    fpr = perfdata['ROC']['fpr']\n",
    "    plt.plot(fpr, tpr,\n",
    "             label='{0} ({1:0.2f})'\n",
    "             ''.format(modelname, auc),\n",
    "             color=current_palette[i], linestyle='-', linewidth=3)\n",
    "    i += 1\n",
    "\n",
    "title = \"Receiver Operating Characteristic\"\n",
    "value = \"ROC\"\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot is the ROC curve for each model. The y-axis is the true-positive (correct positive assignment) rate and x-axis is the false-positive (incorrect positve assignment) rate. Curves nearer to the top-left corner are considered good models while models whose curve lies near the dotted line are considered poor models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All three binary classifiers essentially show the same performance as determined from the ROC, AUC, and confusion matrix values. The independent test dataset contained 175 rows and each classifer correclty predicted 125 of the true response values. The classifiers differed slightly in the assignment for TN, FN, and FP. Given the relatively low number of events in the testing data it is difficult to say that one classifier greatly exceeds another one. A much larger training and testing dataset would certainly help to decide which model is best. Additional data would also allow for more features in the training dataset that could improve the overall model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataByKey(pddata, key, targetcol, trainFraction=0.25):\n",
    "    \"\"\"\n",
    "    Split the data into test and train data\n",
    "    \n",
    "    Inputs:\n",
    "      > pddata: the model feature data (DataFrame)\n",
    "      > key: a key to split the train/test data on\n",
    "      > targetcol: the name of the target column\n",
    "      > trainFraction (0.25 by default): fraction of events to use for training\n",
    "      \n",
    "    Outputs:\n",
    "      > Training feature data (DataFrame), Testing feature data (DataFrame), Training target data (Series), Testing target data (Series)\n",
    "    \"\"\"\n",
    "    keydata = [str(x) for x in list(pddata[key].unique())]\n",
    "    print(\"There are {0} unique keys.\".format(len(keydata)))\n",
    "    print(\"Using {0} training fraction.\".format(trainFraction))\n",
    "    from random import sample\n",
    "    from numpy import asarray\n",
    "    trainKeys = list(sample(keydata, int(trainFraction*len(keydata))))\n",
    "    testKeys = [e for e in keydata if e not in trainKeys]\n",
    "    \n",
    "    if len(set(trainKeys).intersection(testKeys)) > 0:\n",
    "        print(\"There are common keys in train/test!!\")\n",
    "        return None\n",
    "    \n",
    "    trainKeys = asarray(trainKeys)\n",
    "    testKeys  = asarray(testKeys)\n",
    "    print(\"There are {0} keys in the training data.\".format(trainKeys.shape[0]))\n",
    "    print(\"There are {0} keys in the testing data.\".format(testKeys.shape[0]))\n",
    "        \n",
    "    trainData = pddata[pddata[key].isin(trainKeys)].copy()\n",
    "    testData  = pddata[pddata[key].isin(testKeys)].copy()\n",
    "    \n",
    "    return trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = clock(\"Creating Test/Train Datasets Using SplitKey {0}\".format(splitKey))\n",
    "\n",
    "if splitKey is not None:\n",
    "    ## If we're splitting on a key\n",
    "    X_train, X_test, y_train, y_test = splitDataByKey(data, key=splitKey, targetcol=targetcol, trainFraction=0.25)\n",
    "    featureNames = X_train.columns\n",
    "    transformers={\"X\": None, \"y\": None}\n",
    "else:\n",
    "    ## If we're randomly splitting\n",
    "    features, target = splitFeaturesTarget(data, targetcol)\n",
    "\n",
    "    ## Transform (if needed)\n",
    "    retval   = transformData(extra, features, target)\n",
    "    features = retval['X_data']\n",
    "    target   = retval['y_data']\n",
    "    X_scaler = retval['X_scaler']\n",
    "    y_scaler = retval['y_scaler']\n",
    "\n",
    "    ## Split test/train\n",
    "    print(\"Spliting test and train data\")\n",
    "    X_train, X_test, y_train, y_test = splitData(features, target, trainFraction=0.33)\n",
    "    featureNames = X_train.columns\n",
    "    transformers={\"X\": X_scaler, \"y\": y_scaler}\n",
    "    \n",
    "## Save everything\n",
    "data = {\"testDataX\": X_test, \"testDataY\": y_test, \"trainDataX\": X_train, \"trainDataY\": y_train, \n",
    "        \"transformers\": transformers, \"features\": featureNames}\n",
    "for name,value in data.items():\n",
    "    saveData(value, name=name, outdir=outdatadir, dataSuffix=dataSuffix, extra=extra)\n",
    "\n",
    "elapsed(start, comment=\"Created Test/Train Datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainXGBoost(name, X_train, y_train):\n",
    "    name = 'xgboost'\n",
    "    start = clock(\"Training {0}\".format(name))\n",
    "    xgb = xgboost.XGBRegressor(n_jobs=2)\n",
    "    config = {'njobs': 2, 'grid': {'min_child_weight': [500], 'max_depth': [8], 'learning_rate': [0.1], 'gamma': [0.3]}}\n",
    "\n",
    "    tune = True\n",
    "    if tune is True:\n",
    "        tuneResults = tuneEstimator(name, xgb, X_train, y_train, config, debug=True)\n",
    "        model = tuneResults['estimator']\n",
    "    else:\n",
    "        params = {'min_child_weight': 500, 'max_depth': 10, 'learning_rate': 0.1, 'gamma': 0.3}\n",
    "        xgb.set_params(**params)\n",
    "        model = trainEstimator(name, xgb, X_train, y_train)    \n",
    "    elapsed(start, comment=\"Trained {0}\".format(name))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "from pandas import Series\n",
    "from datetime import datetime as dt\n",
    "from numpy import prod\n",
    "from sklearn.base import ClassifierMixin,RegressorMixin\n",
    "from xgboost.sklearn import XGBRegressor, XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "\n",
    "###########################################################################\n",
    "#\n",
    "# Train Model\n",
    "#\n",
    "###########################################################################\n",
    "def trainEstimator(name, estimator, X_train, y_train, debug = False):\n",
    "    \"\"\"\n",
    "    Train a scikit-learn estimator\n",
    "    \n",
    "    Inputs:\n",
    "      > name: string\n",
    "      > estimator: a scikit-learn estimator (Regressor or Classifier)\n",
    "      > X_train: the training data (DataFrame)\n",
    "      > y_train: the response data (DataFrame or Series)\n",
    "      > debug: (False) set to True for print statements\n",
    "      \n",
    "    Output: scikit-learn estimator (although not needed since fit results are stored in estimator)\n",
    "    \"\"\"\n",
    "    if debug:\n",
    "        startTime = dt.now()\n",
    "        print(\"Training {0} on {1} rows and {2} features.\".format(name, X_train.shape[0], X_train.shape[1]))\n",
    "    estimator.fit(X_train, y_train)\n",
    "    if debug:\n",
    "        endTime = dt.now()\n",
    "        delta = endTime-startTime\n",
    "        totaltime = delta.seconds\n",
    "    \n",
    "        if totaltime > 60:\n",
    "            units = \"min\"\n",
    "            totaltime /= 60.0\n",
    "        else:\n",
    "            units = \"sec\"\n",
    "        \n",
    "        totaltime = round(totaltime,1)\n",
    "        print(\"Time to train {0} is {1} {2}.\".format(name, totaltime, units))\n",
    "        \n",
    "    return estimator\n",
    "\n",
    "\n",
    "\n",
    "###########################################################################\n",
    "#\n",
    "# Predict Model\n",
    "#\n",
    "###########################################################################\n",
    "def predictEstimator(name, estimator, X_test, y_test = None, y_scaler = None, debug = False):\n",
    "    \"\"\"\n",
    "    Predict response from a scikit-learn estimator\n",
    "    \n",
    "    Inputs:\n",
    "      > name: string\n",
    "      > estimator: a scikit-learn estimator (Regressor or Classifier)\n",
    "      > X_test: the test data (DataFrame)\n",
    "      > y_test: (None) the test response data (DataFrame or Series) (for formating)\n",
    "      > y_scaler: (None) if the response requires transformation\n",
    "      > debug: (False) set to True for print statements\n",
    "      \n",
    "    Output: Dictionary {\"probs\": class probabilities (if Classifer),\n",
    "                        \"labels\": class labels (if Classifier),\n",
    "                        \"values\": response values (if Regressor}\n",
    "    \"\"\"\n",
    "    \n",
    "    if debug:\n",
    "        startTime = dt.now()\n",
    "        print(\"Predicting {0} on {1} rows and {2} features.\".format(name, X_test.shape[0], X_test.shape[1]))\n",
    "        \n",
    "    if isinstance(estimator, ClassifierMixin):\n",
    "        probs  = getProbabilities(name, estimator, X_test)\n",
    "        probs.index = X_test.index\n",
    "        labels = getPredictions(name, estimator, X_test)\n",
    "        labels.index = X_test.index\n",
    "    else:\n",
    "        probs  = None\n",
    "        labels = None\n",
    "    \n",
    "    if isinstance(estimator, RegressorMixin):\n",
    "        values = getPredictions(name, estimator, X_test)\n",
    "        values.index = X_test.index\n",
    "    else:\n",
    "        values = None\n",
    "\n",
    "    ## Invert predicted data\n",
    "    if y_scaler is not None:\n",
    "        values = invertTransform(values, y_scaler)\n",
    "        values.index = X_test.index\n",
    "\n",
    "    retval = {\"probs\": probs, \"labels\": labels, \"values\": values}\n",
    "    \n",
    "    if debug:\n",
    "        endTime = dt.now()\n",
    "        delta = endTime-startTime\n",
    "        totaltime = delta.seconds\n",
    "    \n",
    "        if totaltime > 60:\n",
    "            units = \"min\"\n",
    "            totaltime /= 60.0\n",
    "        else:\n",
    "            units = \"sec\"\n",
    "        \n",
    "        totaltime = round(totaltime,1)\n",
    "        print(\"Time to predict {0} is {1} {2}.\".format(name, totaltime, units))\n",
    "\n",
    "    return retval \n",
    "\n",
    "\n",
    "def getProbabilities(name, estimator, X_test, debug = False):\n",
    "    \"\"\"\n",
    "    Predict class probabilities from a trained estimator\n",
    "    \n",
    "    Inputs:\n",
    "      > name: string\n",
    "      > estimator: a scikit-learn estimator (Regressor or Classifier)\n",
    "      > X_test: the test data (DataFrame)\n",
    "      > debug: (False) set to True for print statements\n",
    "      \n",
    "    Output:\n",
    "      > pandas.Series of class probabilities\n",
    "    \"\"\"\n",
    "\n",
    "    if debug:\n",
    "        print(\"  Computing target probabilities for {0}\".format(name))\n",
    "    probs  = estimator.predict_proba(X_test)[:,1]\n",
    "    probs  = Series(data=probs, name=\"predicted\")\n",
    "    #probs.index = y_test.index\n",
    "    return probs\n",
    "\n",
    "def getPredictions(name, estimator, X_test, debug = False):\n",
    "    \"\"\"\n",
    "    Predict class labels (Classifier) or response (Regressor) from a trained estimator\n",
    "    \n",
    "    Inputs:\n",
    "      > name: string\n",
    "      > estimator: a scikit-learn estimator (Regressor or Classifier)\n",
    "      > X_test: the test data (DataFrame)\n",
    "      > debug: (False) set to True for print statements\n",
    "      \n",
    "    Output:\n",
    "      > pandas.Series of class labels/response\n",
    "    \"\"\"\n",
    "    \n",
    "    if debug:\n",
    "        print(\"  Computing target predictions for {0}\".format(name))\n",
    "    preds  = estimator.predict(X_test)\n",
    "    preds  = Series(data=preds, name=\"predicted\")\n",
    "    #preds.index = y_test.index\n",
    "    return preds\n",
    "\n",
    "\n",
    "\n",
    "###########################################################################\n",
    "#\n",
    "# Tune Estimator\n",
    "#\n",
    "###########################################################################\n",
    "def tuneEstimator(modelname, estimator, X_train, y_train, config, debug = False):\n",
    "    \"\"\"\n",
    "    Hyperparameter tune a scikit-learn estimator\n",
    "    \n",
    "    Inputs:\n",
    "      > modelname: string\n",
    "      > estimator: a scikit-learn estimator (Regressor or Classifier)\n",
    "      > X_train: the training data (DataFrame)\n",
    "      > y_train: the response data (DataFrame or Series)\n",
    "      > config: Dictionary {\"grid\": Dictionary of parameters to scan (example below),\n",
    "                            \"njobs\": number of parallel threads (jobs),\n",
    "                            \"type\": \"grid\" or \"random\",\n",
    "                            \"iter\": number of random iterations to test (10 if not specified)}\n",
    "      > debug: (False) set to True for print statements\n",
    "\n",
    "        Example grid for xgboost: grid = {'min_child_weight': [10, 100, 1000], 'max_depth': [2, 6, 10], 'learning_rate': 0.1, 'gamma': 0.3}\n",
    "        \n",
    "    Output:\n",
    "      > pandas.Series of class labels/response\n",
    "    \"\"\"\n",
    "    \n",
    "    if debug:\n",
    "        print(\"Tuning a {0} estimator\".format(modelname))\n",
    "        verbose=1\n",
    "    else:\n",
    "        verbose=0\n",
    "    \n",
    "    if estimator is None:\n",
    "        print(\"There is no estimator with parameters information.\")\n",
    "        return {\"estimator\": None, \"params\": None, \"cv\": None}\n",
    "\n",
    "\n",
    "    if config.get('grid') is not None:\n",
    "        grid = config['grid']\n",
    "    else:\n",
    "        if isinstance(estimator, [XGBRegressor, XGBClassifier]):\n",
    "            grid = {'min_child_weight': [10, 100, 1000], 'max_depth': [2, 6, 10], 'learning_rate': 0.1, 'gamma': 0.3}\n",
    "        else:\n",
    "            print(\"No grid for {0}\".format(modelname))\n",
    "            return {\"estimator\": estimator, \"params\": estimator.get_params(), \"cv\": None}\n",
    "\n",
    "\n",
    "    scorers = []\n",
    "    if isinstance(estimator, ClassifierMixin):\n",
    "        scorers = [\"accuracy\", \"average_precision\", \"f1\", \"f1_micro\",\n",
    "                   \"f1_macro\", \"f1_weighted\", \"f1_samples\", \"neg_log_loss\",\n",
    "                   \"precision\", \"recall\", \"roc_auc\"]\n",
    "        scorer = \"roc_auc\"\n",
    "    \n",
    "\n",
    "    if isinstance(estimator, RegressorMixin):\n",
    "        scorers = [\"explained_variance\", \"neg_mean_absolute_error\",\n",
    "                   \"neg_mean_squared_error\", \"neg_mean_squared_log_error\",\n",
    "                   \"neg_median_absolute_error\", \"r2\"]\n",
    "        scorer = \"neg_mean_absolute_error\"\n",
    "\n",
    "    if scorer not in scorers:\n",
    "        raise ValueError(\"Scorer {0} is not allowed\".format(scorer))\n",
    "\n",
    "    searchType = config.get('type')\n",
    "    if searchType is None:\n",
    "        searchType = \"random\"\n",
    "    if config.get('njobs') is not None:\n",
    "        njobs = config['njobs']\n",
    "    else:\n",
    "        njobs = 2\n",
    "        \n",
    "    if searchType == \"grid\":\n",
    "        tuneEstimator = GridSearchCV(estimator, param_grid=grid, cv=2,\n",
    "                                     scoring=scorer, verbose=verbose, n_jobs=njobs)\n",
    "    elif searchType == \"random\":\n",
    "        n_iter_search = config.get('iter')\n",
    "        if n_iter_search is None:\n",
    "            nMax  = 10\n",
    "            n_iter_search = min(nMax, prod([len(x) for x in config['grid'].values()]))         \n",
    "        tuneEstimator = RandomizedSearchCV(estimator, param_distributions=grid,\n",
    "                                           cv=2, n_iter=n_iter_search,\n",
    "                                           verbose=verbose, n_jobs=njobs,\n",
    "                                           return_train_score=True)\n",
    "    else:\n",
    "        raise ValueError(\"Search type {0} is not allowed\".format(searchType))\n",
    "\n",
    "    if debug:\n",
    "        print(\"Running {0} parameter search\".format(searchType))\n",
    "    tuneEstimator.fit(X_train, y_train)\n",
    "    bestEstimator = tuneEstimator.best_estimator_        \n",
    "    bestScore     = tuneEstimator.best_score_\n",
    "    bestParams    = tuneEstimator.best_params_\n",
    "    cvResults     = tuneEstimator.cv_results_\n",
    "    cvScores      = cvResults['mean_test_score']\n",
    "    fitTimes      = cvResults['mean_fit_time']\n",
    "\n",
    "    if debug:\n",
    "        print(\"Tested {0} Parameter Sets\".format(len(fitTimes)))\n",
    "        print(\"CV Fit Time Info (Mean,Std): ({0} , {1})\".format(round(fitTimes.mean(),1), round(fitTimes.std(),1)))\n",
    "        print(\"Best Score                 : {0}\".format(round(bestScore, 3)))\n",
    "        print(\"Worst Score                : {0}\".format(round(min(cvScores), 3)))\n",
    "        print(\"CV Test Scores (Mean,Std)  : ({0} , {1})\".format(round(cvScores.mean(),1), round(cvScores.std(),1)))\n",
    "        print(\"Best Parameters\")\n",
    "        for paramName, paramVal in bestParams.items():\n",
    "            print(\"Param: {0} = {1}\".format(paramName, paramVal))    \n",
    "\n",
    "    return {\"estimator\": bestEstimator, \"params\": bestParams, \"cv\": cvResults}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
